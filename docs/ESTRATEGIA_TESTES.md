# ğŸ§ª EstratÃ©gia de Testes - Guia Completo para QAs

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [PirÃ¢mide de Testes](#-pirÃ¢mide-de-testes)
- [Categorias de Testes](#-categorias-de-testes)
- [PadrÃµes e ConvenÃ§Ãµes](#-padrÃµes-e-convenÃ§Ãµes)
- [Executando Testes](#-executando-testes)
- [Escrevendo Novos Testes](#-escrevendo-novos-testes)
- [Troubleshooting](#-troubleshooting)

---

## ğŸ¯ VisÃ£o Geral

Este projeto implementa uma **estratÃ©gia de testes abrangente** seguindo as melhores prÃ¡ticas da indÃºstria, com foco em **qualidade, manutenibilidade e confiabilidade**.

### Objetivos da EstratÃ©gia

1. **ConfianÃ§a**: Garantir que mudanÃ§as nÃ£o quebrem funcionalidades existentes
2. **DocumentaÃ§Ã£o Viva**: Testes servem como documentaÃ§Ã£o executÃ¡vel
3. **Feedback RÃ¡pido**: Detectar problemas o mais cedo possÃ­vel
4. **Qualidade**: Manter cobertura >= 95% em todo o cÃ³digo
5. **ReferÃªncia**: Servir como exemplo de boas prÃ¡ticas para QAs

### MÃ©tricas Atuais

```
ğŸ“Š Cobertura:  98.77% (meta: 95%)
âœ… Testes:     335 testes (100% passando)
â±ï¸  Tempo:     ~2.4s (unit + integration)
ğŸ­ E2E:        ~45s (Playwright)
```

---

## ğŸ”º PirÃ¢mide de Testes

### DistribuiÃ§Ã£o Ideal

```
        /\
       /E2E\      10-15% - Fluxos crÃ­ticos end-to-end
      /------\
     /  INT  \    20-30% - IntegraÃ§Ã£o entre mÃ³dulos
    /----------\
   /   UNIT    \  60-70% - LÃ³gica de negÃ³cio isolada
  /--------------\
```

### DistribuiÃ§Ã£o Atual vs Ideal

| Categoria | Atual | Ideal | Status |
|-----------|-------|-------|--------|
| **Unit** | 75% (~250) | 60-70% | âœ… BOM |
| **Integration** | 4% (~15) | 20-30% | ğŸ”´ BAIXO |
| **E2E** | 21% (~70) | 10-15% | âš ï¸ ALTO |

**Plano de AÃ§Ã£o**: Rebalancear pirÃ¢mide criando mais testes de integraÃ§Ã£o.

---

## ğŸ“š Categorias de Testes

### 1. ğŸ§ª Testes UnitÃ¡rios (`tests/unit/`)

#### Objetivo
Testar **unidades isoladas** de cÃ³digo (funÃ§Ãµes, classes, mÃ©todos) sem dependÃªncias externas.

#### CaracterÃ­sticas
- âœ… **RÃ¡pidos**: < 100ms por teste
- âœ… **Isolados**: Sem I/O, banco de dados, APIs externas
- âœ… **DeterminÃ­sticos**: Sempre mesmo resultado
- âœ… **Focados**: Um comportamento por teste

#### Quando Usar
- Validar lÃ³gica de negÃ³cio
- Testar edge cases e validaÃ§Ãµes
- Testar formataÃ§Ã£o e transformaÃ§Ã£o de dados
- Testar cÃ¡lculos e algoritmos

#### Estrutura
```
tests/unit/
â”œâ”€â”€ agents/              # Testes de agentes
â”‚   â”œâ”€â”€ test_dispatcher.py
â”‚   â”œâ”€â”€ test_factory.py
â”‚   â””â”€â”€ test_pipeline.py
â”œâ”€â”€ backend/             # Testes de API
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_middleware.py
â”‚   â””â”€â”€ test_validation.py
â””â”€â”€ core/                # Testes de utilitÃ¡rios
    â”œâ”€â”€ test_cache.py
    â”œâ”€â”€ test_config.py
    â”œâ”€â”€ test_formatter.py
    â”œâ”€â”€ test_llm_provider.py
    â””â”€â”€ test_validators.py
```

#### Exemplo
```python
# tests/unit/core/test_validators.py
def test_sanitize_input_remove_caracteres_controle():
    \"\"\"
    Testa que sanitize_input remove caracteres de controle.
    
    Categoria: Unit Test
    Objetivo: Validar sanitizaÃ§Ã£o de input
    Edge Case: Caracteres de controle (\\x00, \\x01, etc)
    \"\"\"
    # Arrange
    input_text = "teste\\x00\\x01\\x02"
    
    # Act
    result = sanitize_input(input_text)
    
    # Assert
    assert "\\x00" not in result
    assert "\\x01" not in result
    assert "\\x02" not in result
    assert "teste" in result
```

#### PadrÃµes
- âœ… Usar **mocks** para dependÃªncias externas
- âœ… Seguir padrÃ£o **AAA** (Arrange, Act, Assert)
- âœ… Nome descritivo: `test_<funcao>_<cenario>_<resultado_esperado>`
- âœ… Docstring explicando objetivo e edge case

---

### 2. ğŸ”„ Testes de IntegraÃ§Ã£o (`tests/integration/`)

#### Objetivo
Testar **interaÃ§Ã£o entre mÃ³dulos** sem mockar tudo, validando que componentes funcionam juntos.

#### CaracterÃ­sticas
- â±ï¸ **Moderados**: 100ms - 1s por teste
- ğŸ”— **Integrados**: Testa comunicaÃ§Ã£o entre mÃ³dulos
- ğŸ¯ **Realistas**: Usa dependÃªncias reais quando possÃ­vel
- ğŸ“¦ **Escopo MÃ©dio**: Testa fluxo entre 2-3 componentes

#### Quando Usar
- Validar integraÃ§Ã£o entre agentes e pipeline
- Testar cache com API real
- Validar middleware com endpoints
- Testar LLM provider com dispatcher
- Validar formatters com pipeline

#### Estrutura
```
tests/integration/
â”œâ”€â”€ test_agent_pipeline_integration.py    # Agentes + Pipeline
â”œâ”€â”€ test_cache_api_integration.py         # Cache + API
â”œâ”€â”€ test_cache_advanced.py                # Cache avanÃ§ado
â”œâ”€â”€ test_fallback.py                      # Fallback entre LLMs
â”œâ”€â”€ test_llm_dispatcher_integration.py    # LLM + Dispatcher
â”œâ”€â”€ test_middleware_endpoints.py          # Middleware + Endpoints
â””â”€â”€ test_user_flow.py                     # Fluxo completo
```

#### Exemplo
```python
# tests/integration/test_cache_api_integration.py
@pytest.mark.integration
def test_cache_hit_on_duplicate_request(client: TestClient):
    \"\"\"
    Testa que cache funciona corretamente em requests duplicadas.
    
    Categoria: Integration Test
    Objetivo: Validar integraÃ§Ã£o Cache + API
    Fluxo: Request 1 (miss) â†’ Cache â†’ Request 2 (hit)
    \"\"\"
    # Arrange
    cache = get_cache()
    cache.clear()
    pergunta = "O que Ã© WCAG?"
    
    # Act - Primeira request (cache miss)
    response1 = client.post("/api/chat", json={"pergunta": pergunta})
    
    # Act - Segunda request (cache hit)
    response2 = client.post("/api/chat", json={"pergunta": pergunta})
    
    # Assert - Ambas retornam 200
    assert response1.status_code == 200
    assert response2.status_code == 200
    
    # Assert - Respostas sÃ£o idÃªnticas
    assert response1.json() == response2.json()
    
    # Assert - EstatÃ­sticas de cache
    stats = cache.get_stats()
    assert stats["hits"] >= 1
    assert stats["misses"] >= 1
```

#### PadrÃµes
- âœ… Usar **TestClient** para API
- âœ… Mockar apenas **dependÃªncias externas** (APIs de terceiros)
- âœ… Limpar estado entre testes (`cache.clear()`)
- âœ… Validar **efeitos colaterais** (cache, logs, mÃ©tricas)

---

### 3. ğŸ­ Testes End-to-End (`tests/e2e/`)

#### Objetivo
Testar **fluxos completos** da perspectiva do usuÃ¡rio, incluindo frontend e backend.

#### CaracterÃ­sticas
- ğŸŒ **Lentos**: 1s - 10s por teste
- ğŸŒ **Completos**: Testa sistema inteiro
- ğŸ‘¤ **Perspectiva do UsuÃ¡rio**: Simula interaÃ§Ã£o real
- ğŸ¯ **CrÃ­ticos**: Apenas fluxos essenciais

#### Quando Usar
- Validar fluxos crÃ­ticos de usuÃ¡rio
- Testar acessibilidade (WCAG)
- Validar responsividade
- Testar compatibilidade entre navegadores
- Validar seguranÃ§a (XSS, CSRF)

#### Estrutura
```
tests/e2e/playwright/
â”œâ”€â”€ conftest.py                          # Fixtures Playwright
â”œâ”€â”€ pages/                               # Page Object Model
â”‚   â”œâ”€â”€ base_page.py
â”‚   â”œâ”€â”€ chat_page.py
â”‚   â””â”€â”€ components/
â”œâ”€â”€ helpers/                             # Helpers
â”‚   â””â”€â”€ assertions.py
â”œâ”€â”€ test_accessibility.py                # Testes WCAG
â”œâ”€â”€ test_accessibility_advanced.py       # Testes WCAG avanÃ§ados
â”œâ”€â”€ test_api_playwright.py               # Testes de API
â”œâ”€â”€ test_browser_compatibility.py        # Compatibilidade
â”œâ”€â”€ test_error_handling.py               # Tratamento de erros
â”œâ”€â”€ test_focus_management.py             # Gerenciamento de foco
â”œâ”€â”€ test_frontend_playwright.py          # Testes de frontend
â”œâ”€â”€ test_performance.py                  # Performance
â”œâ”€â”€ test_responsive_detailed.py          # Responsividade
â”œâ”€â”€ test_security.py                     # SeguranÃ§a
â””â”€â”€ test_ui_interactions.py              # InteraÃ§Ãµes UI
```

#### Exemplo
```python
# tests/e2e/playwright/test_frontend_playwright.py
@pytest.mark.e2e
@pytest.mark.playwright
def test_send_message_flow(page: Page, base_url: str):
    \"\"\"
    Testa fluxo completo de envio de mensagem.
    
    Categoria: E2E Test
    Objetivo: Validar fluxo crÃ­tico de usuÃ¡rio
    Fluxo: Abrir app â†’ Digitar â†’ Enviar â†’ Ver resposta
    \"\"\"
    # Arrange
    chat_page = ChatPage(page, base_url)
    chat_page.navigate()
    
    # Act
    chat_page.send_message("O que Ã© acessibilidade digital?")
    
    # Assert
    chat_page.wait_for_user_message()
    chat_page.wait_for_assistant_message()
    
    last_message = chat_page.get_last_message_text(role="assistant")
    assert len(last_message) > 50
    assert "acessibilidade" in last_message.lower()
```

#### PadrÃµes
- âœ… Usar **Page Object Model** (POM)
- âœ… **Waits determinÃ­sticos** (`expect()`, nÃ£o `wait_for_timeout()`)
- âœ… Capturar **screenshots** em falhas
- âœ… Gravar **vÃ­deos** de execuÃ§Ã£o
- âœ… Testar em **mÃºltiplos navegadores**

---

### 4. ğŸ“ Testes de Contrato (`tests/contract/`)

#### Objetivo
Validar que **contratos de API** nÃ£o quebram entre versÃµes.

#### CaracterÃ­sticas
- âš¡ **RÃ¡pidos**: < 500ms por teste
- ğŸ“‹ **Schemas**: Valida estrutura de request/response
- ğŸ”’ **Backward Compatibility**: Previne breaking changes
- ğŸ“š **DocumentaÃ§Ã£o**: Serve como spec da API

#### Quando Usar
- Validar estrutura de requests
- Validar estrutura de responses
- Prevenir breaking changes
- Documentar contratos de API

#### Exemplo
```python
# tests/contract/test_api_contract.py
@pytest.mark.contract
def test_chat_endpoint_response_contract():
    \"\"\"
    Valida contrato de response do endpoint /api/chat.
    
    Categoria: Contract Test
    Objetivo: Prevenir breaking changes na API
    Valida: Estrutura, tipos e campos obrigatÃ³rios
    \"\"\"
    # Arrange
    client = TestClient(app)
    
    # Act
    response = client.post("/api/chat", json={"pergunta": "teste"})
    
    # Assert - Status
    assert response.status_code == 200
    
    # Assert - Estrutura
    data = response.json()
    assert "resposta" in data
    
    # Assert - Campos obrigatÃ³rios
    resposta = data["resposta"]
    required_fields = [
        "introducao", "corpo", "conclusao",
        "exemplos", "testes_sugeridos", 
        "materiais_estudo", "dica_final"
    ]
    for field in required_fields:
        assert field in resposta, f"Campo obrigatÃ³rio '{field}' ausente!"
    
    # Assert - Tipos
    assert isinstance(resposta["introducao"], str)
    assert isinstance(resposta["exemplos"], list)
```

---

### 5. âš¡ Testes de Performance (`tests/performance/`)

#### Objetivo
Validar **performance** e **escalabilidade** sob carga.

#### CaracterÃ­sticas
- ğŸŒ **Lentos**: 10s - 60s por teste
- ğŸ“Š **MÃ©tricas**: LatÃªncia, throughput, recursos
- ğŸ¯ **SLAs**: Valida requisitos de performance
- ğŸ”¥ **Carga**: Simula mÃºltiplos usuÃ¡rios

#### Quando Usar
- Validar tempo de resposta
- Testar rate limiting
- Validar escalabilidade
- Detectar memory leaks
- Testar sob carga

#### Exemplo
```python
# tests/performance/test_load.py
@pytest.mark.performance
def test_response_time_sla(client: TestClient):
    \"\"\"
    Valida que 95% das requests respondem em < 2s.
    
    Categoria: Performance Test
    Objetivo: Validar SLA de latÃªncia
    SLA: P95 < 2000ms
    \"\"\"
    # Arrange
    num_requests = 100
    times = []
    
    # Act
    for _ in range(num_requests):
        start = time.time()
        client.post("/api/chat", json={"pergunta": "teste"})
        end = time.time()
        times.append(end - start)
    
    # Assert
    times.sort()
    p95 = times[int(len(times) * 0.95)]
    assert p95 < 2.0, f"P95 latency {p95}s excede SLA de 2s"
```

---

### 6. ğŸ”’ Testes de SeguranÃ§a (`tests/security/`)

#### Objetivo
Validar **seguranÃ§a** contra vetores de ataque conhecidos.

#### CaracterÃ­sticas
- â±ï¸ **Moderados**: 500ms - 2s por teste
- ğŸ›¡ï¸ **OWASP Top 10**: Cobre principais vulnerabilidades
- ğŸ¯ **Vetores**: Testa mÃºltiplos payloads maliciosos
- ğŸ” **DetecÃ§Ã£o**: Valida que ataques sÃ£o bloqueados

#### Quando Usar
- Validar sanitizaÃ§Ã£o de input
- Testar proteÃ§Ã£o contra XSS
- Testar proteÃ§Ã£o contra SQL injection
- Validar CSRF protection
- Testar rate limiting

#### Exemplo
```python
# tests/security/test_security_advanced.py
@pytest.mark.security
def test_sql_injection_protection(client: TestClient):
    \"\"\"
    Valida proteÃ§Ã£o contra SQL injection.
    
    Categoria: Security Test
    Objetivo: Validar sanitizaÃ§Ã£o de input
    Vetores: OWASP SQL Injection payloads
    \"\"\"
    # Arrange
    sql_payloads = [
        "' OR '1'='1",
        "'; DROP TABLE users--",
        "1' UNION SELECT NULL--",
    ]
    
    # Act & Assert
    for payload in sql_payloads:
        response = client.post("/api/chat", json={"pergunta": payload})
        
        # Deve sanitizar ou rejeitar
        assert response.status_code in [200, 400]
        
        # Resposta nÃ£o deve conter evidÃªncias de SQL
        if response.status_code == 200:
            data = response.json()
            response_str = str(data).lower()
            assert "sql" not in response_str
            assert "syntax error" not in response_str
```

---

## ğŸ¨ PadrÃµes e ConvenÃ§Ãµes

### Nomenclatura de Testes

```python
# âœ… BOM: Descritivo e claro
def test_sanitize_input_remove_caracteres_controle():
    pass

# âŒ RUIM: Vago e nÃ£o descritivo
def test_sanitize():
    pass
```

### PadrÃ£o AAA (Arrange, Act, Assert)

```python
def test_exemplo():
    # Arrange - Preparar dados e mocks
    input_data = "teste"
    expected = "TESTE"
    
    # Act - Executar funÃ§Ã£o sob teste
    result = funcao_sob_teste(input_data)
    
    # Assert - Verificar resultado
    assert result == expected
```

### Docstrings

```python
def test_exemplo():
    \"\"\"
    DescriÃ§Ã£o do que o teste valida.
    
    Categoria: Unit/Integration/E2E/Contract/Performance/Security
    Objetivo: O que estÃ¡ sendo testado
    Edge Case: Caso especÃ­fico sendo validado (opcional)
    \"\"\"
    pass
```

### Fixtures

```python
# conftest.py
@pytest.fixture
def client():
    \"\"\"Cliente HTTP para testes de API.\"\"\"
    return TestClient(app)

@pytest.fixture(autouse=True)
def clear_cache():
    \"\"\"Limpa cache antes de cada teste.\"\"\"
    cache = get_cache()
    cache.clear()
    yield
    cache.clear()
```

---

## ğŸš€ Executando Testes

### Comandos BÃ¡sicos

```bash
# Todos os testes
pytest -v

# Apenas unit tests
pytest tests/unit/ -v

# Apenas integration tests
pytest tests/integration/ -v

# Apenas E2E tests
pytest tests/e2e/ -v

# Por categoria (marker)
pytest -m unit -v
pytest -m integration -v
pytest -m e2e -v
```

### Com Cobertura

```bash
# Cobertura completa
pytest --cov=src --cov-report=html --cov-report=term

# Cobertura de mÃ³dulo especÃ­fico
pytest --cov=src.chatbot_acessibilidade.core --cov-report=term-missing
```

### Testes EspecÃ­ficos

```bash
# Arquivo especÃ­fico
pytest tests/unit/core/test_validators.py -v

# Teste especÃ­fico
pytest tests/unit/core/test_validators.py::test_sanitize_input_basico -v

# Testes que contÃªm palavra
pytest -k "sanitize" -v
```

### Makefile

```bash
# Instalar dependÃªncias
make install

# Executar testes
make test
make test-unit
make test-integration
make test-e2e

# Com cobertura
make test-cov

# Testes Playwright
make test-playwright
make test-playwright-ui  # Com UI visÃ­vel
```

---

## âœï¸ Escrevendo Novos Testes

### 1. Escolher Categoria

**Pergunte-se**:
- Testa uma funÃ§Ã£o isolada? â†’ **Unit**
- Testa integraÃ§Ã£o entre mÃ³dulos? â†’ **Integration**
- Testa fluxo completo de usuÃ¡rio? â†’ **E2E**
- Valida contrato de API? â†’ **Contract**
- Testa performance? â†’ **Performance**
- Testa seguranÃ§a? â†’ **Security**

### 2. Criar Arquivo

```bash
# Unit test
touch tests/unit/core/test_novo_modulo.py

# Integration test
touch tests/integration/test_nova_integracao.py

# E2E test
touch tests/e2e/playwright/test_novo_fluxo.py
```

### 3. Template Base

```python
\"\"\"
DescriÃ§Ã£o do mÃ³dulo de testes.
\"\"\"
import pytest

pytestmark = pytest.mark.unit  # ou integration, e2e, etc


def test_cenario_basico():
    \"\"\"
    Testa cenÃ¡rio bÃ¡sico.
    
    Categoria: Unit Test
    Objetivo: Validar comportamento padrÃ£o
    \"\"\"
    # Arrange
    input_data = "teste"
    
    # Act
    result = funcao_sob_teste(input_data)
    
    # Assert
    assert result == "esperado"


def test_edge_case_entrada_vazia():
    \"\"\"
    Testa edge case: entrada vazia.
    
    Categoria: Unit Test
    Objetivo: Validar tratamento de entrada vazia
    Edge Case: Input vazio ou None
    \"\"\"
    # Arrange
    input_data = ""
    
    # Act
    result = funcao_sob_teste(input_data)
    
    # Assert
    assert result == ""  # ou comportamento esperado
```

---

## ğŸ”§ Troubleshooting

### Testes Falhando

```bash
# Ver traceback completo
pytest -v --tb=long

# Ver apenas primeira falha
pytest -x

# Ver output de print
pytest -s

# Modo debug
pytest --pdb
```

### Testes Lentos

```bash
# Ver duraÃ§Ã£o de cada teste
pytest --durations=10

# Executar apenas testes rÃ¡pidos
pytest -m "not slow"
```

### Cache de Testes

```bash
# Limpar cache
pytest --cache-clear

# Ver cache
pytest --cache-show
```

---

## ğŸ“Š MÃ©tricas e RelatÃ³rios

### Cobertura

```bash
# Gerar relatÃ³rio HTML
pytest --cov=src --cov-report=html

# Abrir relatÃ³rio
open htmlcov/index.html
```

### RelatÃ³rios HTML

```bash
# Gerar relatÃ³rio de testes
pytest --html=report.html --self-contained-html
```

### CI/CD

Testes sÃ£o executados automaticamente no GitHub Actions:
- âœ… Em cada push
- âœ… Em cada pull request
- âœ… Diariamente (testes de acessibilidade)

---

## ğŸ¯ Checklist de Qualidade

### Antes de Commitar
- [ ] Todos os testes passam
- [ ] Cobertura >= 95%
- [ ] Linters sem erros
- [ ] Testes seguem padrÃµes
- [ ] Docstrings completas

### Antes de PR
- [ ] Testes de integraÃ§Ã£o passam
- [ ] Testes E2E passam
- [ ] Sem testes skipped sem justificativa
- [ ] DocumentaÃ§Ã£o atualizada

---

## ğŸ“š ReferÃªncias

- [Pytest Documentation](https://docs.pytest.org/)
- [Playwright Documentation](https://playwright.dev/python/)
- [Testing Best Practices](https://testingjavascript.com/)
- [WCAG 2.2](https://www.w3.org/WAI/WCAG22/quickref/)

---

**Ãšltima atualizaÃ§Ã£o**: 2025-11-26
**VersÃ£o**: 2.0
**Autor**: Equipe de QA
