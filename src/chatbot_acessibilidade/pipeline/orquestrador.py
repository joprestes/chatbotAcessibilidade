"""
Orquestrador do Pipeline de Acessibilidade.

Este m√≥dulo cont√©m a classe PipelineOrquestrador que gerencia o fluxo completo
de execu√ß√£o dos agentes especializados em acessibilidade digital.
"""

import asyncio
import logging
import json
from typing import Dict, Tuple, Union

from chatbot_acessibilidade.agents.dispatcher import get_agent_response
from chatbot_acessibilidade.config import settings
from chatbot_acessibilidade.core.constants import ErrorMessages
from chatbot_acessibilidade.core.exceptions import APIError, AgentError, ValidationError
from chatbot_acessibilidade.core.formatter import (
    eh_erro,
    extrair_primeiro_paragrafo,
    formatar_resposta_final,
    gerar_dica_final,
)
from chatbot_acessibilidade.core.metrics import MetricsContext, record_request

logger = logging.getLogger(__name__)


def _tratar_resultado_paralelo(
    resultado: Union[str, Exception], nome_agente: str, fallback: str
) -> str:
    """
    Trata o resultado de um agente executado em paralelo.

    Args:
        resultado: Resultado do agente (pode ser Exception ou string)
        nome_agente: Nome do agente para logging
        fallback: Mensagem de fallback em caso de erro

    Returns:
        String com o resultado ou mensagem de fallback
    """
    if isinstance(resultado, Exception):
        logger.warning(f"Erro ao gerar sugest√µes de {nome_agente}: {resultado}")
        return fallback

    if eh_erro(resultado):
        logger.warning(f"Erro detectado na resposta do {nome_agente}")
        return fallback

    return resultado


class PipelineOrquestrador:
    """
    Orquestrador do pipeline de gera√ß√£o de respostas sobre acessibilidade digital.

    Gerencia o fluxo completo de execu√ß√£o dos agentes especializados:
    1. Assistente: Gera resposta inicial
    2. Validador: Valida e corrige tecnicamente
    3. Revisor: Simplifica a linguagem
    4. Testador: Gera plano de testes (paralelo)
    5. Aprofundador: Busca refer√™ncias (paralelo)

    Attributes:
        pergunta: Pergunta do usu√°rio sobre acessibilidade
        resposta_inicial: Resposta gerada pelo assistente
        resposta_validada: Resposta ap√≥s valida√ß√£o t√©cnica
        resposta_final: Resposta ap√≥s revis√£o de linguagem
        testes: Plano de testes gerado
        aprofundar: Refer√™ncias e materiais de estudo
    """

    def __init__(self):
        """Inicializa o orquestrador do pipeline."""
        self.pergunta: str = ""
        self.resposta_inicial: str = ""
        self.resposta_validada: str = ""
        self.resposta_final: str = ""
        self.testes: str = ""
        self.aprofundar: str = ""

    def validar_entrada(self, pergunta: str) -> None:
        """
        Valida a entrada do usu√°rio.

        Args:
            pergunta: Pergunta do usu√°rio a ser validada

        Raises:
            ValidationError: Se a pergunta n√£o atender aos crit√©rios de valida√ß√£o
        """
        pergunta = pergunta.strip()
        if not pergunta:
            raise ValidationError(ErrorMessages.PERGUNTA_VAZIA)

        if len(pergunta) < settings.min_question_length:
            raise ValidationError(
                ErrorMessages.PERGUNTA_MUITO_CURTA.format(min=settings.min_question_length)
            )

        if len(pergunta) > settings.max_question_length:
            raise ValidationError(
                ErrorMessages.PERGUNTA_MUITO_LONGA.format(max=settings.max_question_length)
            )

        self.pergunta = pergunta
        logger.info(f"Iniciando pipeline para pergunta: {pergunta[:50]}...")

    async def executar_sequencial(self) -> None:
        """
        Executa os agentes sequencialmente: Assistente ‚Üí Validador ‚Üí Revisor.

        Cada etapa tem fallback para a etapa anterior em caso de erro.
        M√©tricas s√£o coletadas para cada agente usando MetricsContext.
        """
        # 1. Agente Assistente: Gera a primeira vers√£o da resposta
        logger.debug("Executando agente Assistente...")
        with MetricsContext(agent_name="assistente"):
            try:
                # O agente assistente j√° tem instru√ß√£o completa, apenas passamos a pergunta
                self.resposta_inicial = await get_agent_response(
                    "assistente", self.pergunta, "assistente"
                )

                if eh_erro(self.resposta_inicial):
                    logger.error(f"Erro na resposta inicial: {self.resposta_inicial}")
                    raise AgentError(
                        ErrorMessages.AGENT_ERROR_INITIAL.format(error=self.resposta_inicial)
                    )

                logger.debug("Agente Assistente executado com sucesso")
            except (APIError, AgentError) as e:
                logger.error(f"Erro no agente assistente: {e}")
                raise

        # 2. Agente Validador: Valida e corrige tecnicamente
        logger.debug("Executando agente Validador...")
        with MetricsContext(agent_name="validador"):
            try:
                # Validador recebe a resposta do assistente para validar
                prompt_validador = (
                    f"Analise esta resposta t√©cnica sobre acessibilidade digital:\n\n"
                    f"{self.resposta_inicial}"
                )
                resposta_validacao = await get_agent_response(
                    "validador", prompt_validador, "validador"
                )

                if eh_erro(resposta_validacao):
                    logger.warning("Erro na resposta do validador, usando resposta inicial")
                    self.resposta_validada = self.resposta_inicial
                elif resposta_validacao.strip() == "OK":
                    # Validador aprovou, mant√©m resposta original
                    logger.debug("Validador aprovou a resposta (OK)")
                    self.resposta_validada = self.resposta_inicial
                else:
                    # Validador corrigiu, usa resposta corrigida
                    logger.debug("Validador corrigiu a resposta")
                    self.resposta_validada = resposta_validacao

            except (APIError, AgentError) as e:
                logger.warning(f"Erro no agente validador: {e}, usando resposta inicial")
                self.resposta_validada = self.resposta_inicial  # Fallback

        # 3. Agente Revisor: Simplifica a linguagem
        logger.debug("Executando agente Revisor...")
        with MetricsContext(agent_name="revisor"):
            try:
                # Revisor recebe a resposta validada para simplificar
                prompt_revisor = (
                    "Revise este texto sobre acessibilidade digital para linguagem "
                    "simples e inclusiva:\n\n"
                    f"{self.resposta_validada}"
                )
                self.resposta_final = await get_agent_response("revisor", prompt_revisor, "revisor")

                if eh_erro(self.resposta_final):
                    logger.warning("Erro na resposta do revisor, usando resposta validada")
                    self.resposta_final = self.resposta_validada
                else:
                    logger.debug("Agente Revisor executado com sucesso")

            except (APIError, AgentError) as e:
                logger.warning(f"Erro no agente revisor: {e}, usando resposta validada")
                self.resposta_final = self.resposta_validada  # Fallback

    async def executar_paralelo(self) -> Tuple[str, str]:
        """
        Executa os agentes Testador e Aprofundador em paralelo.

        Returns:
            Tupla com (testes, aprofundar) - resultados dos agentes paralelos
        """
        logger.debug("Executando agentes paralelos (Testador + Aprofundador)...")

        # Prepara prompts para os agentes paralelos
        # Testador recebe pergunta + resposta final
        prompt_testes = (
            "Crie um plano de testes pr√°ticos para validar esta solu√ß√£o de "
            "acessibilidade:\n\n"
            f"Pergunta: {self.pergunta}\n\n"
            f"Resposta: {self.resposta_final}"
        )

        # Aprofundador recebe apenas a pergunta (busca refer√™ncias)
        prompt_aprofundar = (
            "Busque refer√™ncias e materiais de estudo confi√°veis sobre este tema:\n\n"
            f"Pergunta: {self.pergunta}"
        )

        # Executa as tarefas em paralelo
        task_testes = get_agent_response("testador", prompt_testes, "teste")
        task_aprofundar = get_agent_response("aprofundador", prompt_aprofundar, "aprofundar")

        try:
            resultados_paralelos = await asyncio.gather(
                task_testes, task_aprofundar, return_exceptions=True
            )
            testes_result, aprofundar_result = resultados_paralelos

            # Tratamento de erro para os resultados paralelos
            testes_result_typed: Union[str, Exception] = (
                testes_result if isinstance(testes_result, (str, Exception)) else str(testes_result)
            )
            aprofundar_result_typed: Union[str, Exception] = (
                aprofundar_result
                if isinstance(aprofundar_result, (str, Exception))
                else str(aprofundar_result)
            )

            # Mede tempo para cada agente paralelo
            with MetricsContext(agent_name="testador"):
                self.testes = _tratar_resultado_paralelo(
                    testes_result_typed,
                    "testes",
                    "N√£o foi poss√≠vel gerar sugest√µes de testes desta vez.",
                )

            with MetricsContext(agent_name="aprofundador"):
                self.aprofundar = _tratar_resultado_paralelo(
                    aprofundar_result_typed,
                    "aprofundamento",
                    "N√£o foi poss√≠vel gerar sugest√µes de aprofundamento desta vez.",
                )

            logger.debug("Agentes paralelos executados com sucesso")
            return (self.testes, self.aprofundar)

        except Exception as e:
            logger.error(f"Erro ao executar agentes paralelos: {e}")
            self.testes = "N√£o foi poss√≠vel gerar sugest√µes de testes desta vez."
            self.aprofundar = "N√£o foi poss√≠vel gerar sugest√µes de aprofundamento desta vez."
            return (self.testes, self.aprofundar)

    def formatar_saida(self) -> Dict[str, str]:
        """
        Formata a resposta final usando os formatadores existentes.

        Returns:
            Dicion√°rio com a resposta formatada em se√ß√µes
        """
        # Extrai a introdu√ß√£o (primeiro par√°grafo) da resposta completa
        introducao = extrair_primeiro_paragrafo(self.resposta_final)

        # Cria a vari√°vel para o corpo principal dos conceitos
        corpo_conceitos = self.resposta_final

        # Se a introdu√ß√£o for diferente do texto completo, remove a introdu√ß√£o do corpo
        # Isso evita que o mesmo par√°grafo apare√ßa duas vezes
        if introducao.strip() != self.resposta_final.strip():
            corpo_conceitos = self.resposta_final.replace(introducao, "", 1).strip()

        # Gera a dica final com base na pergunta
        dica = gerar_dica_final(self.pergunta, self.resposta_final)

        # Formata a resposta final
        resultado_final: Dict[str, str] = formatar_resposta_final(
            introducao, corpo_conceitos, self.testes, self.aprofundar, dica
        )

        return resultado_final

    async def executar(self, pergunta: str) -> Dict[str, str]:
        """
        Executa o pipeline completo de gera√ß√£o de resposta.

        Args:
            pergunta: Pergunta do usu√°rio sobre acessibilidade digital

        Returns:
            Dicion√°rio com a resposta formatada em se√ß√µes

        Raises:
            ValidationError: Se a pergunta n√£o for v√°lida
            APIError: Se houver erro na comunica√ß√£o com a API
            AgentError: Se houver erro na execu√ß√£o dos agentes
        """
        # Registra requisi√ß√£o para m√©tricas
        record_request()

        # Valida entrada
        self.validar_entrada(pergunta)

        # Verifica se √© uma solicita√ß√£o de simula√ß√£o de persona
        if pergunta.strip().startswith("/simular"):
            logger.info("Detectado comando de simula√ß√£o de persona")
            try:
                # Remove o comando
                resto = pergunta.replace("/simular", "", 1).strip()
                
                # Tenta extrair a persona (primeira palavra)
                partes = resto.split(" ", 1)
                if len(partes) < 2:
                    return {"erro": "Formato inv√°lido. Use: /simular [persona] [contexto]. Ex: /simular cega Como fa√ßo login?"}
                
                persona_raw = partes[0].lower()
                contexto = partes[1]

                # Mapeamento de comandos inclusivos para personas internas
                mapa_personas = {
                    "leitor-tela": "Cega",
                    "cega": "Cega", # Mant√©m compatibilidade
                    "zoom-contraste": "Baixa Vis√£o",
                    "baixa_visao": "Baixa Vis√£o",
                    "teclado": "Motora",
                    "motora": "Motora",
                    "linguagem-simples": "Cognitiva",
                    "cognitiva": "Cognitiva"
                }
                
                persona_nome = mapa_personas.get(persona_raw, persona_raw)

                # Executa o agente de persona
                prompt_persona = f"Persona: {persona_nome}\nContexto: {contexto}"
                resposta_persona = await get_agent_response(
                    "persona", 
                    prompt_persona, 
                    "persona"
                )

                return {
                    "üé≠ **An√°lise de Cen√°rio**": f"**Persona:** {persona_nome.capitalize()}\n\n{resposta_persona}",
                    "‚ÑπÔ∏è **Nota**": "Esta √© uma simula√ß√£o baseada em padr√µes comuns. Pessoas reais podem ter experi√™ncias diferentes."
                }

            except Exception as e:
                logger.error(f"Erro na simula√ß√£o de persona: {e}")
                return {"erro": f"Erro ao simular persona: {str(e)}"}

        # Verifica se √© uma solicita√ß√£o de refatora√ß√£o
        if pergunta.strip().startswith("/refatorar"):
            logger.info("Detectado comando de refatora√ß√£o")
            try:
                # Remove o comando e pega o c√≥digo
                codigo = pergunta.replace("/refatorar", "", 1).strip()
                if not codigo:
                    return {"erro": "Por favor, forne√ßa o c√≥digo que deseja refatorar ap√≥s o comando."}

                # Executa o agente refatorador
                resposta_json = await get_agent_response(
                    "refatorador", 
                    f"Analise e refatore o seguinte c√≥digo:\n\n{codigo}", 
                    "refatorador"
                )

                # Tenta fazer o parse do JSON
                try:
                    # O agente pode retornar markdown de c√≥digo json, removemos se necess√°rio
                    resposta_limpa = resposta_json.replace("```json", "").replace("```", "").strip()
                    dados = json.loads(resposta_limpa)
                    
                    # Formata para o frontend (chaves amig√°veis)
                    return {
                        "üíª **C√≥digo Refatorado**": f"```{dados.get('language', 'html')}\n{dados.get('code', '')}\n```",
                        "üìù **Explica√ß√£o**": dados.get('explanation', ''),
                        "‚úÖ **Crit√©rios WCAG**": "\n".join([f"- {c}" for c in dados.get('wcag_criteria', [])])
                    }
                except json.JSONDecodeError:
                    logger.error(f"Erro ao decodificar JSON do refatorador: {resposta_json}")
                    # Fallback: retorna o texto cru se n√£o for JSON v√°lido
                    return {
                        "‚ö†Ô∏è **Resultado (Formato Bruto)**": resposta_json
                    }

            except Exception as e:
                logger.error(f"Erro no processo de refatora√ß√£o: {e}")
                return {"erro": f"Erro ao refatorar c√≥digo: {str(e)}"}

        # Executa sequencialmente: Assistente ‚Üí Validador ‚Üí Revisor
        await self.executar_sequencial()

        # Executa em paralelo: Testador + Aprofundador
        await self.executar_paralelo()

        # Formata e retorna a resposta final
        return self.formatar_saida()
